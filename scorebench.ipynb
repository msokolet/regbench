{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cultural-choice",
   "metadata": {},
   "source": [
    "# Tutorial for scoring benchmarking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "protecting-mileage",
   "metadata": {},
   "source": [
    "This code loads true and modeled data, then compares the times and results of various scoring approaches. This is a useful companion to regression benchmarking, because the accuracy and duration of cross-validated ridge constraint estimation methods depend on the scoring approach.\n",
    "\n",
    "Written by Michael Sokoletsky, 2023.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f64e517d",
   "metadata": {},
   "source": [
    "### Imports and opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "diverse-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.optimize import fminbound\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import regbench as rb\n",
    "\n",
    "opts = {}\n",
    "# Recording parameters\n",
    "opts['dir'] = 'D:\\Churchland\\Widefield' # Path to directory in which the recording file is located\n",
    "opts['rec_name'] = 'mSM65_09-Jul-2018' # Recording name\n",
    "opts['frames_per_trial'] = 75 # Num of frames per trial\n",
    "opts['dformat'] = 'MATLAB'\n",
    "# Scoring parameters\n",
    "opts['score_mets'] = ['Weighted R2', 'Old corr, float64', 'Old corr, float32', 'New corr'] # Scoring methods to test\n",
    "opts['start'] = 9500 # Number of frames to use for each evaluation\n",
    "opts['n_frames'] = 100 # Number of frames to use for each evaluation\n",
    "opts['n_evals'] = 200 # Number of evaluations to perform\n",
    "opts['alpha_met'] = 'fminbound' # The alpha evaluation method\n",
    "opts['crossval_met'] = 'cross_val_predict' # The alpha evaluation method \n",
    "opts['sample_trials'] = -1 # Number of trials to randomally sample for R2 map calculation. -1 uses all of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "745bce28",
   "metadata": {},
   "source": [
    "### Load real and modeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "behind-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rb.load_data(opts) # Load real widefield data\n",
    "preds = rb.load_results('preds', opts)[0]  # Load modeled data prediction\n",
    "pred = preds[opts['crossval_met'], opts['alpha_met']] # Loads the specific prediction corresponding to the chosen method\n",
    "calc_score = rb.mint_calc_score(data) # Mint a custom score function weighted by component loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce070b",
   "metadata": {},
   "source": [
    "#### Benchmark scoring methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79f6707f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d1fcc52f614a0199af588fd1f638a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Alpha method num:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = {}\n",
    "score_times = {}\n",
    "for score_method in tqdm(opts['score_mets'], desc='Alpha method num'):\n",
    "    st = time.time()\n",
    "    if score_method == 'Weighted R2':\n",
    "        scores[score_method] = calc_score(data.svt, preds[opts['crossval_met'] , opts['alpha_met']])\n",
    "    elif score_method == 'Old corr, float64':\n",
    "        scores[score_method] = np.nanmean(rb.vis_score(data, preds[opts['crossval_met'] , opts['alpha_met']], opts, dtype=np.float64))\n",
    "    elif score_method == 'Old corr, float32':\n",
    "        scores[score_method] = np.nanmean(rb.vis_score(data, preds[opts['crossval_met'] , opts['alpha_met']], opts, dtype=np.float32))\n",
    "    elif score_method == 'New corr':\n",
    "        scores[score_method] = np.nanmean(rb.new_vis_score(data, preds[opts['crossval_met'] , opts['alpha_met']], opts))\n",
    "    score_times[score_method] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "897842af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weighted R2': 0.08078360557556152,\n",
       " 'Old corr, float64': 0.8726661205291748,\n",
       " 'Old corr, float32': 0.42984962463378906,\n",
       " 'New corr': 0.3999300003051758}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "261ccad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weighted R2': 0.36875430291268874,\n",
       " 'Old corr, float64': 0.3805236380070898,\n",
       " 'Old corr, float32': 0.3805236,\n",
       " 'New corr': 0.38052365}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ccf57e542febd893aed97bf7bf7cf91db066c7068f6520e9d01df92e9e89f284"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
